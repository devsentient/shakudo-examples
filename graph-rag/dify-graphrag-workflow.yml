app:
  description: ''
  icon: ðŸ¤–
  icon_background: '#FFEAD5'
  mode: workflow
  name: GraphRAG Workflow
  use_icon_as_answer_icon: false
kind: app
version: 0.1.4
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      allowed_file_extensions:
      - .JPG
      - .JPEG
      - .PNG
      - .GIF
      - .WEBP
      - .SVG
      allowed_file_types:
      - image
      allowed_file_upload_methods:
      - local_file
      - remote_url
      enabled: false
      fileUploadConfig:
        audio_file_size_limit: 50
        batch_count_limit: 5
        file_size_limit: 15
        image_file_size_limit: 10
        video_file_size_limit: 100
        workflow_file_upload_limit: 10
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
      number_limits: 3
    opening_statement: ''
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        isInIteration: false
        sourceType: start
        targetType: http-request
      id: 1737576741264-source-1737580402085-target
      source: '1737576741264'
      sourceHandle: source
      target: '1737580402085'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: http-request
        targetType: code
      id: 1737580402085-source-1737582442936-target
      source: '1737580402085'
      sourceHandle: source
      target: '1737582442936'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: http-request
      id: 1737582442936-source-1737583060814-target
      source: '1737582442936'
      sourceHandle: source
      target: '1737583060814'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: http-request
        targetType: llm
      id: 1737583060814-source-1737645758929-target
      source: '1737583060814'
      sourceHandle: source
      target: '1737645758929'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: end
      id: 1737645758929-source-1737645922282-target
      source: '1737645758929'
      sourceHandle: source
      target: '1737645922282'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        desc: ''
        selected: false
        title: Start
        type: start
        variables:
        - label: prompt
          max_length: 256
          options: []
          required: true
          type: text-input
          variable: prompt
      height: 90
      id: '1737576741264'
      position:
        x: 80
        y: 282
      positionAbsolute:
        x: 80
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        authorization:
          config: null
          type: no-auth
        body:
          data:
          - type: text
            value: '{ "model": "nomic-embed-text", "prompt": "{{#1737576741264.prompt#}}",
              "stream": false }'
          type: raw-text
        desc: ''
        headers: Content-Type:application/x-www-form-urlencoded
        method: post
        params: ''
        selected: false
        timeout:
          max_connect_timeout: 0
          max_read_timeout: 0
          max_write_timeout: 0
        title: Prompt Embed
        type: http-request
        url: http://ollama.hyperplane-ollama.svc.cluster.local:11434/api/embeddings
        variables: []
      height: 126
      id: '1737580402085'
      position:
        x: 383.01102908361906
        y: 282
      positionAbsolute:
        x: 383.01102908361906
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\ndef main(arg1: str) -> dict:\n    return {\n        \"\
          result\": json.loads(arg1)['embedding']\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: array[number]
        selected: false
        title: Code
        type: code
        variables:
        - value_selector:
          - '1737580402085'
          - body
          variable: arg1
      height: 54
      id: '1737582442936'
      position:
        x: 688.8111271555771
        y: 282
      positionAbsolute:
        x: 688.8111271555771
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        authorization:
          config:
            api_key: bmVvNGo6U2hha3VkbzMxMiE=
            header: Authorization
            type: basic
          type: api-key
        body:
          data:
          - id: key-value-3
            key: ''
            type: text
            value: "{ \"statements\": [ {\n\"statement\": \"\nCALL {\n    match (page_node:\
              \ Page)\n    with page_node,\n        vector.similarity.cosine(page_node.embedding,\
              \ {{#1737582442936.result#}}) as score\n    order by score desc\n  \
              \  limit 5\n    return page_node, score\n    \n    union all\n    \n\
              \    match (chunk_node: Chunk)-[:HAS_CHILD]->(page_node:Page)\n    with\
              \ page_node, vector.similarity.cosine(chunk_node.embedding, {{#1737582442936.result#}})\
              \ as score\n    order by score desc\n    limit 5\n    return page_node,\
              \ score\n\n    union all\n    \n    match (question_node: Question)-[:HAS_QUESTION]->(page_node:Page)\n\
              \    with page_node, vector.similarity.cosine(question_node.embedding,\
              \ {{#1737582442936.result#}}) as score\n    order by score desc\n  \
              \  limit 5\n    return page_node, score\n  }\n  \n  with page_node,\
              \ avg(score) as avg_score\n  return page_node.text as text,\n      \
              \  page_node.page_number as page_number,\n        avg_score as score,\n\
              \        page_node.filename as filename\n  order by avg_score desc\n\
              \  limit 5\"\n} ] }"
          type: json
        desc: ''
        headers: Content-Type:application/json
        method: post
        params: ''
        selected: false
        timeout:
          max_connect_timeout: 0
          max_read_timeout: 0
          max_write_timeout: 0
        title: Query Neo4j
        type: http-request
        url: http://neo4j.hyperplane-neo4j.svc.cluster.local:7474/db/neo4j/tx/commit
        variables: []
      height: 126
      id: '1737583060814'
      position:
        x: 993.750649904791
        y: 282
      positionAbsolute:
        x: 993.750649904791
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1737583060814'
          - body
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: qwen2.5:14b-instruct-q4_K_M
          provider: ollama
        prompt_template:
        - id: 7b3fef8f-585c-4bfb-ba23-3078de6dc6ee
          role: system
          text: "<|im_start|>system\nYou are a financial assistant who knows to read\
            \ and understand the financial reports of a company.\nYou help with answering\
            \ question from the user.\nPlease only answer the actual question, don't\
            \ say anything else.\nREMEMBER not to keep the acronyms intact. don't\
            \ try to resolve it.\n\nFrom the provided document, there might be a table\
            \ with markdown format as in:\n\n| Column 1 | Column 2 |\n| Value 1 |\
            \ Value 2 |\n\nThe answer will include 2 parts: the wanted value and the\
            \ page number that contains that value.\n\n<|im_end|>\n<|im_start|>user\n\
            From the following document:\n{{#context#}}\n\nGive me answer for this\
            \ question {{#1737576741264.prompt#}}\n\nNOTE that: \n1. If there are\
            \ several mention of the same terms, please cite every mention in the\
            \ document.\n2. Must not omit page number in the answer.\n3. The answer\
            \ must be coherent and natural to human writing style\n<|im_end|>\n<|im_start|>\
            \ assistant"
        selected: false
        title: LLM
        type: llm
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1737645758929'
      position:
        x: 1296.8111271555772
        y: 282
      positionAbsolute:
        x: 1296.8111271555772
        y: 282
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        outputs:
        - value_selector:
          - '1737645758929'
          - text
          variable: text
        selected: false
        title: End
        type: end
      height: 90
      id: '1737645922282'
      position:
        x: 1600.8111271555772
        y: 282
      positionAbsolute:
        x: 1600.8111271555772
        y: 282
      selected: true
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: -1151.1167524426442
      y: -22.827697709167865
      zoom: 1.050603768881084
